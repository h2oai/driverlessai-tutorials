{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis on a DAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "from h2oai_client import Client, ModelParameters, InterpretParameters\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download, explore, and prepare UCI credit card default data\n",
    "UCI credit card default data: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "The UCI credit card default data contains demographic and payment information about credit card customers in Taiwan in the year 2005. The data set contains 23 input variables:\n",
    "\n",
    "* LIMIT_BAL: Amount of given credit (NT dollar)\n",
    "* SEX: 1 = male; 2 = female\n",
    "* EDUCATION: 1 = graduate school; 2 = university; 3 = high school; 4 = others\n",
    "* MARRIAGE: 1 = married; 2 = single; 3 = others\n",
    "* AGE: Age in years\n",
    "* PAY_0, PAY_2 - PAY_6: History of past payment; PAY_0 = the repayment status in September, 2005; PAY_2 = the repayment status in August, 2005; ...; PAY_6 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; ...; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "* BILL_AMT1 - BILL_AMT6: Amount of bill statement (NT dollar). BILL_AMNT1 = amount of bill statement in September, 2005; BILL_AMT2 = amount of bill statement in August, 2005; ...; BILL_AMT6 = amount of bill statement in April, 2005.\n",
    "* PAY_AMT1 - PAY_AMT6: Amount of previous payment (NT dollar). PAY_AMT1 = amount paid in September, 2005; PAY_AMT2 = amount paid in August, 2005; ...; PAY_AMT6 = amount paid in April, 2005.\n",
    "\n",
    "These 23 input variables are used to predict the target variable, whether or not a customer defaulted on their credit card bill in late 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and clean\n",
    "The credit card default data is available as an .xls file. Pandas reads .xls files automatically, so it's used to load the credit card default data and give the prediction target a shorter name: DEFAULT_NEXT_MONTH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import XLS file\n",
    "path = 'data/default_of_credit_card_clients.xls'\n",
    "data = pd.read_excel(path,\n",
    "                     skiprows=1)\n",
    "\n",
    "#Remove spaces from target column name \n",
    "data = data.rename(columns={'default payment next month': 'DEFAULT_NEXT_MONTH'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for recoding values in the UCI credit card default data\n",
    "This simple function maps longer, more understandable character string values from the UCI credit card default data dictionary to the original integer values of the input variables found in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_cc_data(frame):\n",
    "    \n",
    "    \"\"\" Recodes numeric categorical variables into categorical character variables\n",
    "    with more transparent values. \n",
    "    \n",
    "    Args:\n",
    "        frame: Pandas DataFrame version of UCI credit card default data.\n",
    "        \n",
    "    Returns: \n",
    "        Pandas DataFrame with recoded values.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #Define recoded values\n",
    "    sex_dict = {1:'male', 2:'female'}\n",
    "    education_dict = {0:'other', 1:'graduate school', 2:'university', 3:'high school', \n",
    "                      4:'other', 5:'other', 6:'other'}\n",
    "    marriage_dict = {0:'other', 1:'married', 2:'single', 3:'divorced'}\n",
    "    pay_dict = {-2:'no consumption', -1:'pay duly', 0:'use of revolving credit', 1:'1 month delay', \n",
    "                2:'2 month delay', 3:'3 month delay', 4:'4 month delay', 5:'5 month delay', 6:'6 month delay', \n",
    "                7:'7 month delay', 8:'8 month delay', 9:'9+ month delay'}\n",
    "    \n",
    "    #Recode values using Pandas apply() and anonymous function\n",
    "    frame['SEX'] = frame['SEX'].apply(lambda i: sex_dict[i])\n",
    "    frame['EDUCATION'] = frame['EDUCATION'].apply(lambda i: education_dict[i])    \n",
    "    frame['MARRIAGE'] = frame['MARRIAGE'].apply(lambda i: marriage_dict[i]) \n",
    "    for name in frame.columns:\n",
    "        if name in ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']:\n",
    "            frame[name] = frame[name].apply(lambda i: pay_dict[i])            \n",
    "                \n",
    "    return frame\n",
    "\n",
    "data = recode_cc_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display descriptive statistics for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT_NEXT_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>167484.322667</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>51223.330900</td>\n",
       "      <td>49179.075167</td>\n",
       "      <td>4.701315e+04</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8660.398374</td>\n",
       "      <td>129747.661567</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>73635.860576</td>\n",
       "      <td>71173.768783</td>\n",
       "      <td>6.934939e+04</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "      <td>0.415062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-165580.000000</td>\n",
       "      <td>-69777.000000</td>\n",
       "      <td>-1.572640e+05</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7500.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3558.750000</td>\n",
       "      <td>2984.750000</td>\n",
       "      <td>2.666250e+03</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>22381.500000</td>\n",
       "      <td>21200.000000</td>\n",
       "      <td>2.008850e+04</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22500.250000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>67091.000000</td>\n",
       "      <td>64006.250000</td>\n",
       "      <td>6.016475e+04</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>964511.000000</td>\n",
       "      <td>983931.000000</td>\n",
       "      <td>1.664089e+06</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID       LIMIT_BAL           AGE      BILL_AMT1  \\\n",
       "count  30000.000000    30000.000000  30000.000000   30000.000000   \n",
       "mean   15000.500000   167484.322667     35.485500   51223.330900   \n",
       "std     8660.398374   129747.661567      9.217904   73635.860576   \n",
       "min        1.000000    10000.000000     21.000000 -165580.000000   \n",
       "25%     7500.750000    50000.000000     28.000000    3558.750000   \n",
       "50%    15000.500000   140000.000000     34.000000   22381.500000   \n",
       "75%    22500.250000   240000.000000     41.000000   67091.000000   \n",
       "max    30000.000000  1000000.000000     79.000000  964511.000000   \n",
       "\n",
       "           BILL_AMT2     BILL_AMT3      BILL_AMT4      BILL_AMT5  \\\n",
       "count   30000.000000  3.000000e+04   30000.000000   30000.000000   \n",
       "mean    49179.075167  4.701315e+04   43262.948967   40311.400967   \n",
       "std     71173.768783  6.934939e+04   64332.856134   60797.155770   \n",
       "min    -69777.000000 -1.572640e+05 -170000.000000  -81334.000000   \n",
       "25%      2984.750000  2.666250e+03    2326.750000    1763.000000   \n",
       "50%     21200.000000  2.008850e+04   19052.000000   18104.500000   \n",
       "75%     64006.250000  6.016475e+04   54506.000000   50190.500000   \n",
       "max    983931.000000  1.664089e+06  891586.000000  927171.000000   \n",
       "\n",
       "           BILL_AMT6       PAY_AMT1      PAY_AMT2      PAY_AMT3  \\\n",
       "count   30000.000000   30000.000000  3.000000e+04   30000.00000   \n",
       "mean    38871.760400    5663.580500  5.921163e+03    5225.68150   \n",
       "std     59554.107537   16563.280354  2.304087e+04   17606.96147   \n",
       "min   -339603.000000       0.000000  0.000000e+00       0.00000   \n",
       "25%      1256.000000    1000.000000  8.330000e+02     390.00000   \n",
       "50%     17071.000000    2100.000000  2.009000e+03    1800.00000   \n",
       "75%     49198.250000    5006.000000  5.000000e+03    4505.00000   \n",
       "max    961664.000000  873552.000000  1.684259e+06  896040.00000   \n",
       "\n",
       "            PAY_AMT4       PAY_AMT5       PAY_AMT6  DEFAULT_NEXT_MONTH  \n",
       "count   30000.000000   30000.000000   30000.000000        30000.000000  \n",
       "mean     4826.076867    4799.387633    5215.502567            0.221200  \n",
       "std     15666.159744   15278.305679   17777.465775            0.415062  \n",
       "min         0.000000       0.000000       0.000000            0.000000  \n",
       "25%       296.000000     252.500000     117.750000            0.000000  \n",
       "50%      1500.000000    1500.000000    1500.000000            0.000000  \n",
       "75%      4013.250000    4031.500000    4000.000000            0.000000  \n",
       "max    621000.000000  426529.000000  528666.000000            1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write train and test sets from client to DAI server disk for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/credit_train.csv\"\n",
    "test_path =\"data/credit_test.csv\"\n",
    "if not (os.path.isfile(train_path) and os.path.isfile(test_path)):\n",
    "    train_pd, test_pd = train_test_split(data, test_size=0.3) #Split credticard dataset into train/test\n",
    "    train_pd.to_csv(path_or_buf=\"data/credit_train.csv\", index=False) #Write train set to csv\n",
    "    test_pd.to_csv(path_or_buf=\"data/credit_test.csv\", index=False) #Write test set to csv\n",
    "else:\n",
    "    traid_pd = pd.read_csv(\"data/credit_train.csv\")\n",
    "    test_pd = pd.read_csv(\"data/credit_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to DAI Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = 'localhost'\n",
    "username = 'username'\n",
    "password = 'password'\n",
    "h2oai = Client(address = 'http://' + ip + ':12345', username = username, password = password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data to DAI Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_path_dai = cwd+\"/data/credit_train.csv\" #DAI needs absolute path\n",
    "test_path_dai = cwd+\"/data/credit_test.csv\"  #DAI needs absolute path\n",
    "train = h2oai.create_dataset_sync(train_path_dai)\n",
    "test = h2oai.create_dataset_sync(test_path_dai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup parameters for DAI experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the parameters you want to pass to DAI \n",
    "#These are the same parameters you see in the DAI GUI\n",
    "dataset_key=train.key #Dataset to use for DAI\n",
    "validset_key='' #Validation set to use for DAI (Note, we are not using one for this experiment)\n",
    "testset_key=test.key #Test set to use for DAI\n",
    "target=\"DEFAULT_NEXT_MONTH\" #Target column for DAI\n",
    "dropped_cols=['ID'] #List of columns to drop. In this case we are dropping 'ID'\n",
    "weight_col=None #The column that indicates the per row observation weights. \n",
    "                #If None, each row will have an observation weight of 1\n",
    "fold_col=None #The column that indicates the fold. If None, the folds will be determined by DAI\n",
    "time_col='[OFF]' #Time Column: The column that provides a time order, if applicable.\n",
    "                  #if [AUTO], Driverless AI will auto-detect a potential time order\n",
    "                  #if [OFF], auto-detection is disabled\n",
    "is_time_series=False #Whether or not the experiment is a time series problem\n",
    "classification=True #Inform DAI if the problem type is a classification (binomial/multinomial) \n",
    "                    #or not (regression)\n",
    "enable_gpus=True #Whether or not to enable GPUs\n",
    "seed=1234 #Use seed for reproducibility\n",
    "scorer_str='auc' #Set evaluation metric. In this case we are interested in optimizing AUC\n",
    "accuracy=5 #Accuracy setting for experiment (One of the 3 knobs you see in the DAI UI)\n",
    "time=5 #Time setting for experiment (One of the 3 knobs you see in the DAI UI)\n",
    "interpretability=5 #Interpretability setting for experiment (One of the 3 knobs you see in the DAI UI)\n",
    "config_overrides=None #Extra parameters that can be passed in TOML format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on the experiment settings, refer to the [Experiment Settings](http://docs.h2o.ai/driverless-ai/latest-stable/docs/userguide/launching.html#experimentsettings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview DAI experiment\n",
    "For this example, we will be predicting default payment next month. The parameters that control the experiment process are:  accuracy, time, and interpretability. We can use the get_experiment_preview_sync function to get a sense of what will happen during the experiment.\n",
    "\n",
    "We will start out by seeing what the experiment will look like with accuracy, time, and interpretability all set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACCURACY [5/10]:',\n",
       " '- Training data size: *21,000 rows, 24 cols*',\n",
       " '- Feature evolution: *XGBoost*, *1/3 validation split*',\n",
       " '- Final pipeline: *Ensemble (1xXGBoost), 4-fold CV*',\n",
       " '',\n",
       " 'TIME [5/10]:',\n",
       " '- Feature evolution: *4 individuals*, up to *58 iterations*',\n",
       " '- Early stopping: After *10* iterations of no improvement',\n",
       " '',\n",
       " 'INTERPRETABILITY [5/10]:',\n",
       " '- Feature pre-pruning strategy: None',\n",
       " '- Monotonicity constraints: disabled',\n",
       " '- Feature engineering search space (where applicable): [Clustering, Date, FrequencyEncoding, Identity, Interactions, NumEncoding, TargetEncoding, Text, TruncatedSVD, WeightOfEvidence]',\n",
       " '',\n",
       " 'XGBoost models to train:',\n",
       " '- Model and feature tuning: *16*',\n",
       " '- Feature evolution: *104*',\n",
       " '- Final pipeline: *4*',\n",
       " '',\n",
       " 'Estimated max. total memory usage:',\n",
       " '- Feature engineering: *224.0MB*',\n",
       " '- GPU XGBoost: *24.0MB*',\n",
       " '',\n",
       " 'Estimated runtime: *6 minutes*']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_preview = h2oai.get_experiment_preview_sync(dataset_key=train.key, \n",
    "                                                validset_key=validset_key, \n",
    "                                                classification=classification, \n",
    "                                                dropped_cols=dropped_cols, \n",
    "                                                target_col=target, \n",
    "                                                time_col=time_col, \n",
    "                                                enable_gpus=enable_gpus, \n",
    "                                                accuracy=accuracy, \n",
    "                                                time=time, \n",
    "                                                interpretability=interpretability, \n",
    "                                                config_overrides=config_overrides)\n",
    "exp_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these settings, the Driverless AI experiment should take around 5 minutes to run and will train about 119 models:\n",
    "\n",
    "* 16 for model and feature tuning\n",
    "* 102 for feature evolution\n",
    "* 1 for the final pipeline\n",
    "\n",
    "Driverless AI can suggest the parameters based on the dataset and target column. Below we will use the get_experiment_tuning_suggestion to see what settings Driverless AI suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_key': 'suniduco',\n",
       " 'target_col': 'DEFAULT_NEXT_MONTH',\n",
       " 'weight_col': '',\n",
       " 'fold_col': '',\n",
       " 'orig_time_col': '',\n",
       " 'time_col': '',\n",
       " 'is_classification': True,\n",
       " 'cols_to_drop': [],\n",
       " 'validset_key': '',\n",
       " 'testset_key': '',\n",
       " 'enable_gpus': True,\n",
       " 'seed': False,\n",
       " 'accuracy': 6,\n",
       " 'time': 3,\n",
       " 'interpretability': 6,\n",
       " 'scorer': 'AUC',\n",
       " 'time_groups_columns': [],\n",
       " 'time_period_in_seconds': None,\n",
       " 'num_prediction_periods': None,\n",
       " 'num_gap_periods': None,\n",
       " 'is_timeseries': False,\n",
       " 'config_overrides': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let Driverless suggest parameters for experiment\n",
    "params = h2oai.get_experiment_tuning_suggestion(dataset_key=train.key, \n",
    "                                                target_col=target, \n",
    "                                                is_time_series=is_time_series,\n",
    "                                                is_classification=classification,\n",
    "                                                config_overrides=config_overrides)\n",
    "params.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driverless AI has found that the best parameters are to set accuracy = 6, time = 3, and interpretability = 6. It has selected AUC as the scorer (this is the default scorer for binomial problems)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our experiment preview with the suggested settings below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACCURACY [6/10]:',\n",
       " '- Training data size: *21,000 rows, 24 cols*',\n",
       " '- Feature evolution: *XGBoost*, *1/3 validation split*',\n",
       " '- Final pipeline: *Ensemble (1xGLM, 1xXGBoost), 5-fold CV*',\n",
       " '',\n",
       " 'TIME [3/10]:',\n",
       " '- Feature evolution: *4 individuals*, up to *42 iterations*',\n",
       " '- Early stopping: After *5* iterations of no improvement',\n",
       " '',\n",
       " 'INTERPRETABILITY [6/10]:',\n",
       " '- Feature pre-pruning strategy: FS',\n",
       " '- Monotonicity constraints: disabled',\n",
       " '- Feature engineering search space (where applicable): [Date, FrequencyEncoding, Identity, Interactions, NumEncoding, TargetEncoding, Text, WeightOfEvidence]',\n",
       " '',\n",
       " 'XGBoost models to train:',\n",
       " '- Model and feature tuning: *24*',\n",
       " '- Feature evolution: *64*',\n",
       " '- Final pipeline: *10*',\n",
       " '',\n",
       " 'Estimated max. total memory usage:',\n",
       " '- Feature engineering: *224.0MB*',\n",
       " '- GPU XGBoost: *24.0MB*',\n",
       " '',\n",
       " 'Estimated runtime: *5 minutes*']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_preview = h2oai.get_experiment_preview_sync(dataset_key=dataset_key, \n",
    "                                                validset_key=validset_key, \n",
    "                                                classification=classification, \n",
    "                                                dropped_cols =dropped_cols, \n",
    "                                                target_col=target, \n",
    "                                                time_col=time_col, \n",
    "                                                enable_gpus=enable_gpus, \n",
    "                                                accuracy=params.accuracy, #DAI suggested \n",
    "                                                                            #for accuracy \n",
    "                                                time=params.time, #DAI suggested \n",
    "                                                                    #for time\n",
    "                                                interpretability=params.interpretability, #DAI \n",
    "                                                                #suggested for interpretability\n",
    "                                                config_overrides=config_overrides)\n",
    "exp_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch experiment\n",
    "Launch the experiment using the accuracy, time, and interpretability settings DAI suggested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = h2oai.start_experiment_sync(\n",
    "    \n",
    "    #Datasets\n",
    "    dataset_key=train.key, \n",
    "    validset_key=validset_key,\n",
    "    testset_key=testset_key, \n",
    "    \n",
    "    #Columns\n",
    "    target_col=target,\n",
    "    cols_to_drop=dropped_cols,\n",
    "    weight_col=weight_col,\n",
    "    fold_col=fold_col,\n",
    "    orig_time_col=time_col,\n",
    "    time_col=time_col,\n",
    "    \n",
    "    #Parameters\n",
    "    is_classification=classification,\n",
    "    enable_gpus=enable_gpus,\n",
    "    seed=seed,\n",
    "    accuracy=params.accuracy, #DAI suggested for accuracy\n",
    "    time=params.time, #DAI suggested for time\n",
    "    interpretability=params.interpretability, #DAI suggested for interpretability\n",
    "    scorer=scorer_str,\n",
    "    is_timeseries=is_time_series\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the final model score for the validation and test datasets\n",
    "When feature engineering is complete, an ensemble model can be built depending on the accuracy setting. The experiment object also contains the score on the validation and test data for this ensemble model. In this case, the validation score is the score on the training cross-validation predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Score on Validation Data: 0.784\n",
      "Final Model Score on Test Data: 0.779\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Model Score on Validation Data: \" + str(round(experiment.valid_score, 3)))\n",
    "print(\"Final Model Score on Test Data: \" + str(round(experiment.test_score, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable importance for DAI experiment\n",
    "The table outputted below shows the feature name, its relative importance, and a description. Some features will be engineered by Driverless AI and some can be the original feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Importance</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2_CVTE:PAY_0.0</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375500</td>\n",
       "      <td>3_CVTE:PAY_2.0</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.099910</td>\n",
       "      <td>4_CVTE:PAY_3.0</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077350</td>\n",
       "      <td>18_PAY_AMT2</td>\n",
       "      <td>PAY_AMT2 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074373</td>\n",
       "      <td>5_CVTE:PAY_4.0</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.065621</td>\n",
       "      <td>7_CVTE:PAY_6.0</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.062677</td>\n",
       "      <td>16_LIMIT_BAL</td>\n",
       "      <td>LIMIT_BAL (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.059770</td>\n",
       "      <td>26_NumCatTE:BILL_AMT1:BILL_AMT3:BILL_AMT4:LIMI...</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.055562</td>\n",
       "      <td>10_BILL_AMT1</td>\n",
       "      <td>BILL_AMT1 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.055515</td>\n",
       "      <td>17_PAY_AMT1</td>\n",
       "      <td>PAY_AMT1 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.046339</td>\n",
       "      <td>6_CVTE:PAY_5.0</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.046072</td>\n",
       "      <td>20_PAY_AMT4</td>\n",
       "      <td>PAY_AMT4 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.041787</td>\n",
       "      <td>19_PAY_AMT3</td>\n",
       "      <td>PAY_AMT3 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.038487</td>\n",
       "      <td>25_ClusterTE:ClusterID14:BILL_AMT1:LIMIT_BAL:P...</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.034030</td>\n",
       "      <td>22_PAY_AMT6</td>\n",
       "      <td>PAY_AMT6 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.028074</td>\n",
       "      <td>0_CVTE:EDUCATION.0</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.027590</td>\n",
       "      <td>12_BILL_AMT3</td>\n",
       "      <td>BILL_AMT3 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.023847</td>\n",
       "      <td>15_BILL_AMT6</td>\n",
       "      <td>BILL_AMT6 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.019489</td>\n",
       "      <td>9_AGE</td>\n",
       "      <td>AGE (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.017413</td>\n",
       "      <td>8_CVTE:SEX.0</td>\n",
       "      <td>Out-of-fold mean of the response grouped by: [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.017127</td>\n",
       "      <td>11_BILL_AMT2</td>\n",
       "      <td>BILL_AMT2 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.014052</td>\n",
       "      <td>27_Freq:PAY_2:PAY_5:SEX</td>\n",
       "      <td>Encoding of categorical levels of feature(s) [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.010644</td>\n",
       "      <td>21_PAY_AMT5</td>\n",
       "      <td>PAY_AMT5 (original)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.009543</td>\n",
       "      <td>14_BILL_AMT5</td>\n",
       "      <td>BILL_AMT5 (original)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Relative Importance                                            Feature  \\\n",
       "0              1.000000                                     2_CVTE:PAY_0.0   \n",
       "1              0.375500                                     3_CVTE:PAY_2.0   \n",
       "2              0.099910                                     4_CVTE:PAY_3.0   \n",
       "3              0.077350                                        18_PAY_AMT2   \n",
       "4              0.074373                                     5_CVTE:PAY_4.0   \n",
       "5              0.065621                                     7_CVTE:PAY_6.0   \n",
       "6              0.062677                                       16_LIMIT_BAL   \n",
       "7              0.059770  26_NumCatTE:BILL_AMT1:BILL_AMT3:BILL_AMT4:LIMI...   \n",
       "8              0.055562                                       10_BILL_AMT1   \n",
       "9              0.055515                                        17_PAY_AMT1   \n",
       "10             0.046339                                     6_CVTE:PAY_5.0   \n",
       "11             0.046072                                        20_PAY_AMT4   \n",
       "12             0.041787                                        19_PAY_AMT3   \n",
       "13             0.038487  25_ClusterTE:ClusterID14:BILL_AMT1:LIMIT_BAL:P...   \n",
       "14             0.034030                                        22_PAY_AMT6   \n",
       "15             0.028074                                 0_CVTE:EDUCATION.0   \n",
       "16             0.027590                                       12_BILL_AMT3   \n",
       "17             0.023847                                       15_BILL_AMT6   \n",
       "18             0.019489                                              9_AGE   \n",
       "19             0.017413                                       8_CVTE:SEX.0   \n",
       "20             0.017127                                       11_BILL_AMT2   \n",
       "21             0.014052                            27_Freq:PAY_2:PAY_5:SEX   \n",
       "22             0.010644                                        21_PAY_AMT5   \n",
       "23             0.009543                                       14_BILL_AMT5   \n",
       "\n",
       "                                          Description  \n",
       "0   Out-of-fold mean of the response grouped by: [...  \n",
       "1   Out-of-fold mean of the response grouped by: [...  \n",
       "2   Out-of-fold mean of the response grouped by: [...  \n",
       "3                                 PAY_AMT2 (original)  \n",
       "4   Out-of-fold mean of the response grouped by: [...  \n",
       "5   Out-of-fold mean of the response grouped by: [...  \n",
       "6                                LIMIT_BAL (original)  \n",
       "7   Out-of-fold mean of the response grouped by: [...  \n",
       "8                                BILL_AMT1 (original)  \n",
       "9                                 PAY_AMT1 (original)  \n",
       "10  Out-of-fold mean of the response grouped by: [...  \n",
       "11                                PAY_AMT4 (original)  \n",
       "12                                PAY_AMT3 (original)  \n",
       "13  Out-of-fold mean of the response grouped by: [...  \n",
       "14                                PAY_AMT6 (original)  \n",
       "15  Out-of-fold mean of the response grouped by: [...  \n",
       "16                               BILL_AMT3 (original)  \n",
       "17                               BILL_AMT6 (original)  \n",
       "18                                     AGE (original)  \n",
       "19  Out-of-fold mean of the response grouped by: [...  \n",
       "20                               BILL_AMT2 (original)  \n",
       "21  Encoding of categorical levels of feature(s) [...  \n",
       "22                                PAY_AMT5 (original)  \n",
       "23                               BILL_AMT5 (original)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download Summary\n",
    "import subprocess\n",
    "summary_path=h2oai.download(src_path=experiment.summary_path, dest_dir=\".\")\n",
    "dir_path=\"./h2oai_experiment_summary_\" + experiment.key\n",
    "subprocess.call(['unzip', '-o', summary_path, '-d', dir_path], shell=False)\n",
    "\n",
    "#View Features\n",
    "features = pd.read_table(dir_path + \"/features.txt\", sep=',', skipinitialspace=True)\n",
    "features.head(n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup scoring package from DAI experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./scorer.zip'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2oai.download(experiment.scoring_pipeline_path, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute external processes to install scoring artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "#Unzip scoring package and install the scoring python library\n",
    "unzip scorer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./scoring-pipeline/scoring_h2oai_experiment_koguduvo-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: scoring-h2oai-experiment-sahiguhu==1.0.0 from file:///home/navdeep/h2oai/examples/h2oai_client_demo/mli/scoring-pipeline/scoring_h2oai_experiment_sahiguhu-1.0.0-py3-none-any.whl in /home/navdeep/h2oai/env/lib/python3.6/site-packages\n",
      "Installing collected packages: scoring-h2oai-experiment-koguduvo\n",
      "Successfully installed scoring-h2oai-experiment-koguduvo-1.0.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Import scoring module\n",
    "!pip install scoring-pipeline/scoring_h2oai_experiment_*.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import scoring package installed directly above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring_h2oai_experiment_koguduvo import Scorer #Make sure to add experiment name to  \n",
    "                                                     #import scoring_h2oai_experiment_* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Create a singleton Scorer instance.\n",
    "#For optimal performance, create a Scorer instance once, and call score() or score_batch() multiple times.\n",
    "scorer = Scorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LIMIT_BAL',\n",
       " 'SEX',\n",
       " 'EDUCATION',\n",
       " 'AGE',\n",
       " 'PAY_0',\n",
       " 'PAY_2',\n",
       " 'PAY_3',\n",
       " 'PAY_4',\n",
       " 'PAY_5',\n",
       " 'PAY_6',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check colum names used for scorer()\n",
    "scorer.get_column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scorer.score_batch(test_pd).drop('DEFAULT_NEXT_MONTH.0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_DEFAULT_NEXT_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.223650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.723660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.120519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_DEFAULT_NEXT_MONTH\n",
       "0              0.728522\n",
       "1              0.223650\n",
       "2              0.723660\n",
       "3              0.120519\n",
       "4              0.059630"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = scores.rename(columns={\"DEFAULT_NEXT_MONTH.1\": \"p_DEFAULT_NEXT_MONTH\"})\n",
    "assert scores.shape[0] == test_pd.shape[0], \"Test set rows and score rows should match!\"\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform sensitivity analysis to test model performance on unseen data\n",
    "Sensitivity analysis investigates whether model behavior and outputs remain stable when data is intentionally perturbed or other changes are simulated in data. Beyond traditional assessment practices, sensitivity analysis of machine learning model predictions is perhaps the most important validation technique for machine learning models. Machine learning models can make drastically differing predictions for only minor changes in input variable values. In practice, many linear model validation techniques focus on the numerical instability of regression parameters due to correlation between input variables or between input variables and the dependent variable. It may be prudent for those switching from linear modeling techniques to machine learning techniques to focus less on numerical instability of model parameters and to focus more on the potential instability of model predictions.\n",
    "\n",
    "Here sensitivity analysis is used to understand the impact of changing one of the most important input variable, PAY_0, and the impact of a sociologically sensitive variable, SEX, in the model. If the model changes in reasonable and expected ways when important variable values are changed this can enhance trust in the model. If the contribution of potentially sensitive variables, such as those related to gender, race, age, marital status, or disability status, can be shown to have minimal impact on the model, this is an indication of fairness in the model predictions and can also increase overall trust in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bind new model predictions onto test data\n",
    "Typically, a productive exercise in model debugging and validation is to investigate customers with very high or low predicted probabilities to determine if their predictions stay within reasonable bounds when important variables are changed. The predictions from the new, more accurate model are merged onto the test set to find these potentially interesting customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT_NEXT_MONTH</th>\n",
       "      <th>p_DEFAULT_NEXT_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26648</td>\n",
       "      <td>40000</td>\n",
       "      <td>male</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>26</td>\n",
       "      <td>2 month delay</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>2 month delay</td>\n",
       "      <td>...</td>\n",
       "      <td>39103</td>\n",
       "      <td>38945</td>\n",
       "      <td>2000</td>\n",
       "      <td>3900</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1545</td>\n",
       "      <td>360000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>34</td>\n",
       "      <td>1 month delay</td>\n",
       "      <td>no consumption</td>\n",
       "      <td>no consumption</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13963</td>\n",
       "      <td>30000</td>\n",
       "      <td>female</td>\n",
       "      <td>high school</td>\n",
       "      <td>married</td>\n",
       "      <td>54</td>\n",
       "      <td>2 month delay</td>\n",
       "      <td>2 month delay</td>\n",
       "      <td>2 month delay</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>...</td>\n",
       "      <td>27972</td>\n",
       "      <td>27374</td>\n",
       "      <td>3600</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>2300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>354</td>\n",
       "      <td>80000</td>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>43</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>...</td>\n",
       "      <td>19036</td>\n",
       "      <td>19414</td>\n",
       "      <td>3177</td>\n",
       "      <td>2600</td>\n",
       "      <td>3000</td>\n",
       "      <td>1691</td>\n",
       "      <td>695</td>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2177</td>\n",
       "      <td>320000</td>\n",
       "      <td>male</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "      <td>35</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>...</td>\n",
       "      <td>18627</td>\n",
       "      <td>19167</td>\n",
       "      <td>7000</td>\n",
       "      <td>4100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  LIMIT_BAL     SEX        EDUCATION MARRIAGE  AGE  \\\n",
       "0  26648      40000    male  graduate school   single   26   \n",
       "1   1545     360000  female       university   single   34   \n",
       "2  13963      30000  female      high school  married   54   \n",
       "3    354      80000  female       university   single   43   \n",
       "4   2177     320000    male       university   single   35   \n",
       "\n",
       "                     PAY_0                    PAY_2                    PAY_3  \\\n",
       "0            2 month delay  use of revolving credit  use of revolving credit   \n",
       "1            1 month delay           no consumption           no consumption   \n",
       "2            2 month delay            2 month delay            2 month delay   \n",
       "3  use of revolving credit  use of revolving credit  use of revolving credit   \n",
       "4  use of revolving credit  use of revolving credit  use of revolving credit   \n",
       "\n",
       "                     PAY_4          ...          BILL_AMT5 BILL_AMT6  \\\n",
       "0            2 month delay          ...              39103     38945   \n",
       "1                 pay duly          ...                  0         0   \n",
       "2  use of revolving credit          ...              27972     27374   \n",
       "3  use of revolving credit          ...              19036     19414   \n",
       "4  use of revolving credit          ...              18627     19167   \n",
       "\n",
       "   PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0      2000      3900      1500         0      1600      1600   \n",
       "1         0         0       700         0         0         0   \n",
       "2      3600         0      1200      2400         0      2300   \n",
       "3      3177      2600      3000      1691       695       882   \n",
       "4      7000      4100      1000      1000      1000      1000   \n",
       "\n",
       "   DEFAULT_NEXT_MONTH  p_DEFAULT_NEXT_MONTH  \n",
       "0                   1              0.728522  \n",
       "1                   1              0.223650  \n",
       "2                   1              0.723660  \n",
       "3                   0              0.120519  \n",
       "4                   0              0.059630  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd.reset_index(drop=True, inplace=True)\n",
    "scores.reset_index(drop=True, inplace=True)\n",
    "test_yhat = pd.concat([test_pd, scores], axis=1)\n",
    "test_yhat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 28743,\n",
       " 99: 16555,\n",
       " 10: 2778,\n",
       " 20: 15643,\n",
       " 30: 10260,\n",
       " 40: 8375,\n",
       " 50: 26256,\n",
       " 60: 25387,\n",
       " 70: 15318,\n",
       " 80: 8399,\n",
       " 90: 17764}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_percentile_dict(yhat, id_, frame):\n",
    "\n",
    "    \"\"\" Returns the minimum, the maximum, and the deciles of a column, yhat, \n",
    "        as the indices based on another column id_.\n",
    "    \n",
    "    Args:\n",
    "        yhat: Column in which to find percentiles.\n",
    "        id_: Id column that stores indices for percentiles of yhat.\n",
    "        frame: Pandas DataFrame containing yhat and id_. \n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of percentile values and index column values.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Create a copy of frame and sort it by yhat\n",
    "    sort_df = frame\n",
    "    sort_df = sort_df.sort_values(yhat)\n",
    "    sort_df = sort_df.reset_index()\n",
    "    \n",
    "    #Find top and bottom percentiles\n",
    "    percentiles_dict = {}\n",
    "    percentiles_dict[0] = sort_df.loc[0, id_]\n",
    "    percentiles_dict[99] = sort_df.loc[sort_df.shape[0]-1, id_]\n",
    "\n",
    "    #Find 10th-90th percentiles\n",
    "    inc = sort_df.shape[0]//10\n",
    "    for i in range(1, 10):\n",
    "        percentiles_dict[i * 10] = sort_df.loc[i * inc,  id_]\n",
    "\n",
    "    return percentiles_dict\n",
    "\n",
    "#Display percentiles dictionary\n",
    "#ID values for rows\n",
    "#from lowest prediction \n",
    "#to highest prediction\n",
    "pred_percentile_dict = get_percentile_dict('p_DEFAULT_NEXT_MONTH', 'ID', test_yhat)\n",
    "pred_percentile_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display test data prediction range\n",
    "Below, we can see that the model produces both very low and very high predictions in test set, indicating that it is likely responsive to signal in new data and not simply predicting the majority class or an average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest prediction:       DEFAULT_NEXT_MONTH  p_DEFAULT_NEXT_MONTH\n",
      "2562                   0              0.027384\n",
      "Highest prediction:       DEFAULT_NEXT_MONTH  p_DEFAULT_NEXT_MONTH\n",
      "3156                   1              0.861882\n"
     ]
    }
   ],
   "source": [
    "y = \"DEFAULT_NEXT_MONTH\"\n",
    "yhat = \"p_DEFAULT_NEXT_MONTH\"\n",
    "print('Lowest prediction:', test_yhat[test_yhat['ID'] == int(pred_percentile_dict[0])][[y, yhat]])\n",
    "print('Highest prediction:', test_yhat[test_yhat['ID'] == int(pred_percentile_dict[99])][[y, yhat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained model to test predictions for interesting situations: customer least likely to default\n",
    "As a starting point for further analysis, sensitivity analysis is performed for the customer least \n",
    "likely to default. This woman has a roughly 0.02 probability of defaulting according to the trained DAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT_NEXT_MONTH</th>\n",
       "      <th>p_DEFAULT_NEXT_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>28743</td>\n",
       "      <td>400000</td>\n",
       "      <td>female</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>29</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>pay duly</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>use of revolving credit</td>\n",
       "      <td>...</td>\n",
       "      <td>70732</td>\n",
       "      <td>68674</td>\n",
       "      <td>62545</td>\n",
       "      <td>53704</td>\n",
       "      <td>4142</td>\n",
       "      <td>5010</td>\n",
       "      <td>66676</td>\n",
       "      <td>66660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  LIMIT_BAL     SEX        EDUCATION MARRIAGE  AGE     PAY_0  \\\n",
       "2562  28743     400000  female  graduate school   single   29  pay duly   \n",
       "\n",
       "         PAY_2                    PAY_3                    PAY_4  \\\n",
       "2562  pay duly  use of revolving credit  use of revolving credit   \n",
       "\n",
       "              ...          BILL_AMT5 BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "2562          ...              70732     68674     62545     53704      4142   \n",
       "\n",
       "      PAY_AMT4  PAY_AMT5  PAY_AMT6  DEFAULT_NEXT_MONTH  p_DEFAULT_NEXT_MONTH  \n",
       "2562      5010     66676     66660                   0              0.027384  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[0])]\n",
    "test_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test effect of changing SEX\n",
    "SEX should not have a large impact on predictions. This could indicate unwanted sociological bias in the DAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Prediction on the first row when SEX is female  0.027383523644371473 ***\n",
      "\n",
      "***Prediction on the first row when SEX is male  0.027087264440276405 ***\n"
     ]
    }
   ],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[0])]\n",
    "test_case = test_case[list(scorer.get_column_names())]\n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "print(\"***Prediction on the first row when SEX is female \", str(score[1]), \"***\\n\")\n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "test_case['SEX'] = 'male'\n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "print(\"***Prediction on the first row when SEX is male \", str(score[1]), \"***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems simulating this person as a male does have a very minimal impact on their probability of default but nothing alarming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test effect of changing PAY_0\n",
    "Variable importance indicates that the value of PAY_0 can have a strong effect on \n",
    "model predictions. Measuring the change in predicted probability when the value of PAY_0 is changed from a \n",
    "timely payment to late payment is probably a good test case for prediction stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Prediction on the first row when PAY_0 remains unchanged  0.0274 ***\n",
      "\n",
      "***Prediction on the first row when PAY_0 goes from 'pay duly' to '2 month delay'  0.2427 ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get original test case and score\n",
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[0])]\n",
    "test_case = test_case[list(scorer.get_column_names())]\n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "print(\"***Prediction on the first row when PAY_0 remains unchanged \", str(\"%.4f\" % score[1]), \"***\\n\")\n",
    "\n",
    "#Change PAY_0 to '2 month delay' and re-score\n",
    "test_case['PAY_0'] = '2 month delay' \n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "print(\"***Prediction on the first row when PAY_0 goes from 'pay duly' to '2 month delay' \", str(\"%.4f\" % score[1]), \"***\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the value is changed from pay duly to two month delay there is a roughly 8.8X increase in predicted probability. Assuming a 0.5 probability cutoff, the predicted outcome is still stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained model to test predictions for interesting situations: customer most likely to default\n",
    "Now the same test will be performed on the customer most likely to default. This man has a roughly 0.86 probability of default according to the trained DAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT_NEXT_MONTH</th>\n",
       "      <th>p_DEFAULT_NEXT_MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>16555</td>\n",
       "      <td>10000</td>\n",
       "      <td>male</td>\n",
       "      <td>graduate school</td>\n",
       "      <td>single</td>\n",
       "      <td>30</td>\n",
       "      <td>3 month delay</td>\n",
       "      <td>2 month delay</td>\n",
       "      <td>2 month delay</td>\n",
       "      <td>7 month delay</td>\n",
       "      <td>...</td>\n",
       "      <td>2300</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  LIMIT_BAL   SEX        EDUCATION MARRIAGE  AGE          PAY_0  \\\n",
       "3156  16555      10000  male  graduate school   single   30  3 month delay   \n",
       "\n",
       "              PAY_2          PAY_3          PAY_4          ...           \\\n",
       "3156  2 month delay  2 month delay  7 month delay          ...            \n",
       "\n",
       "     BILL_AMT5 BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  \\\n",
       "3156      2300      2300         0         0         0         0         0   \n",
       "\n",
       "      PAY_AMT6  DEFAULT_NEXT_MONTH  p_DEFAULT_NEXT_MONTH  \n",
       "3156         0                   1              0.861882  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[99])]\n",
    "test_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test effect of changing SEX\n",
    "Changing the value for SEX from male to female for this customer slightly increases the predicted probability to about 0.8621, another small change but nothing alarming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Prediction on the first row when SEX is Male  0.8619 ***\n",
      "\n",
      "***Prediction on the first row when SEX is Female  0.8621 ***\n"
     ]
    }
   ],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[99])]\n",
    "test_case = test_case[list(scorer.get_column_names())]\n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "print(\"***Prediction on the first row when SEX is Male \", str(\"%.4f\" % score[1]), \"***\\n\")\n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "test_case['SEX'] = 'female'\n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "print(\"***Prediction on the first row when SEX is Female \", str(\"%.4f\" % score[1]), \"***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test effect of changing PAY_0\n",
    "Switching the riskiest customer's value for PAY_0 from 3 month delay to pay duly reduces the their chance of defaulting from roughly 86% to roughly 66%, a noticable swing in probability but still a higher probability value, markedly greater than the typical 0.5 cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Prediction on the first row when PAY_0 remains unchanged  0.8619 ***\n",
      "\n",
      "***Prediction on the first row when PAY_0 goes from '3 month delay' to 'pay duly'  0.6670 ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get original test case and score\n",
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[99])]\n",
    "test_case = test_case[list(scorer.get_column_names())]\n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "print(\"***Prediction on the first row when PAY_0 remains unchanged \", str(\"%.4f\" % score[1]), \"***\\n\")\n",
    "\n",
    "#Change PAY_0 to 'pay duly' and re-score\n",
    "test_case['PAY_0'] = 'pay duly' \n",
    "score = scorer.score(test_case.values.tolist()[0])\n",
    "print(\"***Prediction on the first row when PAY_0 goes from '3 month delay' to 'pay duly' \", str(\"%.4f\" % score[1]), \"***\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this notebook, a DAI model was trained to predict credit card defaults. Sensitivity analysis was used to test the DAI model for trustworthiness and stability. In a small number of boundary test cases, the trained DAI model appeared somewhat stable. Sensitivity analysis is a powerful model debugging techniques and can increase trust in complex models. This technique should generalize well for many types of business and research problems, enabling you to train a complex model and justify it to your colleagues, bosses, and potentially, external regulators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
