{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driverless AI - Time Series Recipes with Rolling Window\n",
    "\n",
    "The purpose of this notebook is to show an example of using Driverless AI to forecast on dates outside of the forecast horizon.  This can be accomplished in two ways: \n",
    "\n",
    "1. **Re-Training**: Trigger a Driverless AI experiment to be trained once the forecast horizon ends\n",
    "2. **Test Time Augmentation**: Use the same Driverless AI experiment and use Test Time Augmentation to update historical features\n",
    "\n",
    "\n",
    "Let's take our example of forecasting sales for the [Walmart Kaggle Competition](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting). \n",
    "With Re-Training, we would launch a new Driverless AI experiment every week with the latest data and use the resulting model to forecast for the next week. With Test Time Augmentation, we would continue using the same Driverless AI experiment outside of the initial forecast horizon.\n",
    "\n",
    "Both options have their advantages and disadvantages.  By re-training an experiment with the latest data, Driverless AI has the ability to possibly improve the model by changing the features used, choosing a different algorithm, and/or selecting different parameters.  As the data changes over time, for example, Driverless AI may find that the best algorithm for this use case has changed.\n",
    "\n",
    "Using Test Time Augmentation to be able to continue using the same experiment over a longer period of time means there is no need to continually repeat a model review process.  The model may become out of date, however, and the MOJO scoring pipeline is not supported.\n",
    "\n",
    "For different use cases, there may be clear advantages for Re-Training or Test Time Augmentation.  In this notebook, we will show how to implement either option and evaluate how the model performs over time.\n",
    "\n",
    "**Note**: This notebook was tested and run on Driverless AI 1.8.1.\n",
    "\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Import data into Python\n",
    "2. Format data for Time Series\n",
    "3. Perform Re-Training\n",
    "    * create function that slices data by date\n",
    "    * for each slice of data: \n",
    "        * import data into Driverless AI\n",
    "        * train an experiment\n",
    "        * combine test predictions\n",
    "4. Perform Test Time Augmentation\n",
    "    * train an experiment on historical data\n",
    "    * forecast sales over future data using Test Time Augmentation\n",
    "5. Evaluate the performance of Re-Training vs Test Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from h2oai_client import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Data\n",
    "\n",
    "We will begin by importing our data using pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>sample_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  Temperature  Fuel_Price  MarkDown1  \\\n",
       "0      1     1  2010-02-05      24924.50        42.31       2.572       -1.0   \n",
       "1      1     2  2010-02-05      50605.27        42.31       2.572       -1.0   \n",
       "2      1     3  2010-02-05      13740.12        42.31       2.572       -1.0   \n",
       "3      1     4  2010-02-05      39954.04        42.31       2.572       -1.0   \n",
       "4      1     5  2010-02-05      32229.38        42.31       2.572       -1.0   \n",
       "\n",
       "   MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0  211.096358         8.106   \n",
       "1       -1.0       -1.0       -1.0       -1.0  211.096358         8.106   \n",
       "2       -1.0       -1.0       -1.0       -1.0  211.096358         8.106   \n",
       "3       -1.0       -1.0       -1.0       -1.0  211.096358         8.106   \n",
       "4       -1.0       -1.0       -1.0       -1.0  211.096358         8.106   \n",
       "\n",
       "   IsHoliday  sample_weight  \n",
       "0          0              1  \n",
       "1          0              1  \n",
       "2          0              1  \n",
       "3          0              1  \n",
       "4          0              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data = pd.read_csv(\"./walmart_train.csv\")\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime\n",
    "sales_data[\"Date\"] = pd.to_datetime(sales_data[\"Date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Format Data for Time Series\n",
    "\n",
    "The data has one record per Store, Department, and Week.  Our goal for this use case will be to forecast the total sales for the next week.\n",
    "\n",
    "The only features we should use as predictors are ones that we will have available at the time of scoring.  Features like the Temperature, Fuel Price, and Unemployment will not be known in advance.  Therefore, before we start our Driverless AI experiments, we will choose to use the previous week's Temperature, Fuel Price, Unemployment, and CPI attributes.  This information we will know at time of scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_variables = [\"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\"]\n",
    "dai_data = sales_data.set_index([\"Date\", \"Store\", \"Dept\"])\n",
    "lagged_data = dai_data.loc[:, lag_variables].groupby(level=[\"Store\", \"Dept\"]).shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join lagged predictor variables to training data\n",
    "dai_data = dai_data.join(lagged_data.rename(columns=lambda x: x +\"_lag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original predictor variables - we do not want to use these in the model \n",
    "dai_data = dai_data.drop(lagged_data, axis=1)\n",
    "dai_data = dai_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>sample_weight</th>\n",
       "      <th>Temperature_lag</th>\n",
       "      <th>Fuel_Price_lag</th>\n",
       "      <th>CPI_lag</th>\n",
       "      <th>Unemployment_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Store  Dept  Weekly_Sales  MarkDown1  MarkDown2  MarkDown3  \\\n",
       "0 2010-02-05      1     1      24924.50       -1.0       -1.0       -1.0   \n",
       "1 2010-02-05      1     2      50605.27       -1.0       -1.0       -1.0   \n",
       "2 2010-02-05      1     3      13740.12       -1.0       -1.0       -1.0   \n",
       "3 2010-02-05      1     4      39954.04       -1.0       -1.0       -1.0   \n",
       "4 2010-02-05      1     5      32229.38       -1.0       -1.0       -1.0   \n",
       "\n",
       "   MarkDown4  MarkDown5  IsHoliday  sample_weight  Temperature_lag  \\\n",
       "0       -1.0       -1.0          0              1              NaN   \n",
       "1       -1.0       -1.0          0              1              NaN   \n",
       "2       -1.0       -1.0          0              1              NaN   \n",
       "3       -1.0       -1.0          0              1              NaN   \n",
       "4       -1.0       -1.0          0              1              NaN   \n",
       "\n",
       "   Fuel_Price_lag  CPI_lag  Unemployment_lag  \n",
       "0             NaN      NaN               NaN  \n",
       "1             NaN      NaN               NaN  \n",
       "2             NaN      NaN               NaN  \n",
       "3             NaN      NaN               NaN  \n",
       "4             NaN      NaN               NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dai_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Perform Re-Training\n",
    "\n",
    "For Re-Training, we will create a function that slices the data by date.  For each window, we will train a Driverless Ai model on 139 weeks of data and forecast the next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Moving Windows\n",
    "\n",
    "We will create a function that can split our data by time to create multiple experiments.  Our function will split the data into training and testing based on the training length and testing length specified by the user.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moving_windows(dataset, train_len, test_len, date_col):\n",
    "    \n",
    "    # Calculate windows for the training and testing data based on the train_len and test_len arguments\n",
    "    unique_dates = dataset[date_col].unique()\n",
    "    unique_dates.sort()\n",
    "    num_dates = len(unique_dates)\n",
    "    num_windows = (num_dates - train_len) // test_len\n",
    "    print(\"Number of Training Windows: \", num_windows)\n",
    "    \n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        train_start_date = unique_dates[i]\n",
    "        train_end_date = unique_dates[(i + train_len - 1)]\n",
    "        test_start_date = unique_dates[(i + train_len)]\n",
    "        test_end_date = unique_dates[(i + train_len + test_len - 1)]\n",
    "        \n",
    "        window = {'train_start_date': train_start_date, \n",
    "                  'train_end_date': train_end_date, \n",
    "                  'test_start_date': test_start_date,\n",
    "                  'test_end_date': test_end_date}\n",
    "        windows.append(window)\n",
    "        \n",
    "    return windows    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Windows:  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_start_date</th>\n",
       "      <th>train_end_date</th>\n",
       "      <th>test_start_date</th>\n",
       "      <th>test_end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>2012-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>2012-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>2012-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>2012-10-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_start_date train_end_date test_start_date test_end_date\n",
       "0       2010-02-05     2012-09-28      2012-10-05    2012-10-05\n",
       "1       2010-02-12     2012-10-05      2012-10-12    2012-10-12\n",
       "2       2010-02-19     2012-10-12      2012-10-19    2012-10-19\n",
       "3       2010-02-26     2012-10-19      2012-10-26    2012-10-26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([OrderedDict(x) for x in get_moving_windows(dai_data, 139, 1, \"Date\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model per Moving Window\n",
    "\n",
    "Our next function trains the experiment for each subset of data and saves the forecast for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dai_get_forecast(train_data, test_data, predictors, target, date_col, time_group_cols, \n",
    "                     accuracy, time, interpretability):\n",
    "    \n",
    "    # Save dataset\n",
    "    train_path = \"./train_data.csv\"\n",
    "    test_path = \"./test_data.csv\"\n",
    "    keep_cols = predictors + [target, date_col] + time_group_cols\n",
    "    keep_cols = list(set(keep_cols))\n",
    "    train_data[keep_cols].to_csv(train_path, index = False)\n",
    "    test_data[keep_cols].to_csv(test_path, index = False)\n",
    "    \n",
    "    # Add datasets to Driverless AI\n",
    "    train_dai = h2oai.upload_dataset_sync(train_path)\n",
    "    test_dai = h2oai.upload_dataset_sync(test_path)\n",
    "    \n",
    "    # Run Driverless AI Experiment\n",
    "    experiment = h2oai.start_experiment_sync(dataset_key = train_dai.key,\n",
    "                                             target_col = target,\n",
    "                                             cols_to_drop = [],\n",
    "                                             is_classification = False,\n",
    "                                             accuracy = accuracy,\n",
    "                                             time = time,\n",
    "                                             interpretability = interpretability,\n",
    "                                             scorer = \"RMSE\",\n",
    "                                             is_time_series = date_col,\n",
    "                                             time_groups_columns = time_group_cols,\n",
    "                                             num_prediction_periods = test_data[date_col].nunique(),\n",
    "                                             num_gap_periods = 0)\n",
    "    \n",
    "    # Predict on the Test Data\n",
    "    pred_job = h2oai.make_prediction_sync(experiment.key, test_dai.key,\n",
    "                                          output_margin = False, pred_contribs = False)\n",
    "    test_predictions_path = h2oai.download(pred_job.predictions_csv_path, \"./\")\n",
    "    test_predictions = pd.read_csv(test_predictions_path)\n",
    "    test_predictions.columns = [\"Prediction\"]\n",
    "    \n",
    "    # Add predictions to original test data\n",
    "    keep_cols = [target, date_col] + time_group_cols\n",
    "    test_predictions = pd.concat([test_data[keep_cols].reset_index(drop=True), test_predictions], axis = 1)\n",
    "    \n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Re-Training\n",
    "\n",
    "Now that we have our helper functions, we can run Re-Training.\n",
    "\n",
    "For each 139 weeks of data, we will: \n",
    "\n",
    "* train a Driverless AI model\n",
    "* forcast the next week's prediction\n",
    "\n",
    "This will give us 4 weeks of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'http://ip_where_driverless_is_running:12345'\n",
    "username = 'username'\n",
    "password = 'password'\n",
    "h2oai = Client(address = address, username = username, password = password)\n",
    "# make sure to use the same user name and password when signing in through the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Windows:  4\n"
     ]
    }
   ],
   "source": [
    "windows = get_moving_windows(dai_data, train_len = 139, test_len = 1, date_col = \"Date\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_predictions = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\", \"IsHoliday\",\n",
    "              \"Temperature_lag\", \"Fuel_Price_lag\", \"CPI_lag\", \"Unemployment_lag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in windows:\n",
    "    train_data = dai_data[(dai_data[\"Date\"] >= window.get(\"train_start_date\")) & \n",
    "                          (dai_data[\"Date\"] <= window.get(\"train_end_date\"))]\n",
    "\n",
    "    test_data = dai_data[(dai_data[\"Date\"] >= window.get(\"test_start_date\")) & \n",
    "                         (dai_data[\"Date\"] <= window.get(\"test_end_date\"))]\n",
    "\n",
    "    # Get the Driverless AI forecast predictions\n",
    "    preds = dai_get_forecast(train_data, test_data, \n",
    "                             predictors, \n",
    "                             target = \"Weekly_Sales\", \n",
    "                             date_col = \"Date\", \n",
    "                             time_group_cols = [\"Store\", \"Dept\"], \n",
    "                             accuracy = 1, time = 1, interpretability = 10)\n",
    "    forecast_predictions = forecast_predictions.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4: Perform Test Time Augmentation\n",
    "\n",
    "For Test Time Augmentation, we will train a single Driverless AI experiment on the first 139 weeks of data.  We will then use it to forecast the next 4 weeks.\n",
    "\n",
    "Note: Our model is only being told it will need to forecast the next week.  To trigger Test Time Augmentation, I must provide information on everything that happens after the training data ends up until the week I want to forecast for.  For example, let's say my model training data ends on 2012-09-28 and my forecast horizon ends on 2012-10-05 (one week after).  Now if I want to forecast further out, I must provide information about what actually happened on 2012-10-05.  This allows Driverless AI to update any features that use historical information (like what was the sales the week before).\n",
    "\n",
    "When formatting to predict for 2010-10-12, I would create the test data to look like the following: \n",
    "\n",
    "| Date | Store | Dept | Predictors | Weekly_Sales |\n",
    "|------|-------|------|------------|--------------|\n",
    "| 2010-10-05 | 1 | 1 | ... | 21904.47 | \n",
    "| 2010-10-12 | 1 | 1 | ... | NA | \n",
    "\n",
    "\n",
    "When formatting to predict for 2010-10-19, I would create the test data to look like the following: \n",
    "\n",
    "| Date | Store | Dept | Predictors | Weekly_Sales |\n",
    "|------|-------|------|------------|--------------|\n",
    "| 2010-10-05 | 1 | 1 | ... | 21904.47 | \n",
    "| 2010-10-12 | 1 | 1 | ... | 22764.01 | \n",
    "| 2010-10-19 | 1 | 1 | ... | NA | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Driverless AI Experiment\n",
    "\n",
    "Let's begin by training our Driverless AI model.  We will train on data up until 2012-09-28. We will use the following time series parameters:\n",
    "\n",
    "    Time Group Columns: [Store, Dept]\n",
    "    Number of Prediction Periods: 1 (a.k.a., horizon)\n",
    "    Number of Gap Periods: 0\n",
    "\n",
    "Note that the period size is unknown to the Python client. To overcome this, you can also specify the optional `time_period_in_seconds` parameter, which can help specify the horizon in real time units. If this parameter is omitted, Driverless AI will automatically detect the period size in the experiment, and the horizon value will respect this period. I.e., if you are sure your data has 1 week period, you can say `num_prediction_periods=14`, otherwise it is possible that the model may not work out correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dai_data[dai_data[\"Date\"] <= \"2012-09-28\"]\n",
    "test_data = dai_data[dai_data[\"Date\"] >= \"2012-10-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./train_data.csv\"\n",
    "test_path = \"./test_data.csv\"\n",
    "\n",
    "keep_cols = predictors + [\"Weekly_Sales\", \"Date\", \"Dept\", \"Store\"]\n",
    "keep_cols = list(set(keep_cols))\n",
    "\n",
    "train_data[keep_cols].to_csv(train_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add datasets to Driverless AI\n",
    "train_dai = h2oai.upload_dataset_sync(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = h2oai.start_experiment_sync(dataset_key = train_dai.key,\n",
    "                                         target_col = \"Weekly_Sales\",\n",
    "                                         cols_to_drop = [],\n",
    "                                         is_classification = False,\n",
    "                                         accuracy = 1,\n",
    "                                         time = 1,\n",
    "                                         interpretability = 10,\n",
    "                                         scorer = \"RMSE\",\n",
    "                                         time_col = \"Date\",\n",
    "                                         time_groups_columns = [\"Store\", \"Dept\"],\n",
    "                                         num_prediction_periods = 1,\n",
    "                                         num_gap_periods = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Forecast\n",
    "\n",
    "Now that we have trained our single Driverless AI model, we will use it to forecast the next 4 weeks of sales.\n",
    "\n",
    "In order to use the same experiment to forecast past the forecast horizon, we need to use Test Time Augmentation.  Test Time Augmentation means that we want to Driverless AI to augment our test data once it's outside of the forecast horizon.\n",
    "\n",
    "For example, we may find that an important feature in the model is the `Weekly_Sales` from the previous week for a Store and Department.  Once we are outside of the forecast horizon, Driverless AI no longer has the information about what the previous week's `Weekly_Sales` were.  \n",
    "\n",
    "If we provide Driverless AI with test data that consists of the previous weeks' target value, then Driverless AI is able to update these historical features before calculating the forecast.\n",
    "\n",
    "In order to trigger Test Time Augmentation (TTA), we must format our forecast data such that: \n",
    "\n",
    "* the date that we want to forecast for has NA's in the target value\n",
    "* all target values for previous dates are included in the model\n",
    "\n",
    "Here is an example of performing TTA for the second week in our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>409695</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21904.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412671</th>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Store  Dept  Weekly_Sales\n",
       "409695 2012-10-05      1     1      21904.47\n",
       "412671 2012-10-12      1     1           NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forecast for the second week\n",
    "\n",
    "tta_test_data_wk2 = test_data[test_data[\"Date\"] <= \"2012-10-12\"].copy()\n",
    "tta_test_data_wk2.loc[tta_test_data_wk2[\"Date\"] == \"2012-10-12\", \"Weekly_Sales\"] = None\n",
    "\n",
    "tta_test_data_wk2.loc[(tta_test_data_wk2[\"Store\"] == 1) & (tta_test_data_wk2[\"Dept\"] == 1), [\"Date\", \"Store\", \"Dept\", \"Weekly_Sales\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we will send to Driverless AI to score consists of the data for the first week after training with the target value and the data for the second week after training without the target value.\n",
    "\n",
    "We want Driverless AI to give us a prediction for the second week after training, so we leave `Weekly_Sales` as NA.  We also provide information about what happened one week prior.  We need this information to update the historical lags created by the Driverless AI experiment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload test data to Driverless AI\n",
    "test_path = \"./tta_test_data.csv\"\n",
    "tta_test_data_wk2.to_csv(test_path, index = False)\n",
    "tta_test_data_wk2_dai = h2oai.upload_dataset_sync(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "pred_job = h2oai.make_prediction_sync(experiment.key, tta_test_data_wk2_dai.key, \n",
    "                                      output_margin = False, pred_contribs = False)\n",
    "pred_path = h2oai.download(pred_job.predictions_csv_path, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>603.870605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14193.673828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13296.996094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>296.672363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1307.100586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Store  Dept  Weekly_Sales\n",
       "2976 2012-10-12      1     1    603.870605\n",
       "2977 2012-10-12      1     2  14193.673828\n",
       "2978 2012-10-12      1     3  13296.996094\n",
       "2979 2012-10-12      1     4    296.672363\n",
       "2980 2012-10-12      1     5   1307.100586"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Predictions\n",
    "preds = pd.read_csv(pred_path)\n",
    "\n",
    "actual = tta_test_data_wk2[[\"Date\", \"Store\", \"Dept\"]]\n",
    "actual = actual.reset_index(drop = True)\n",
    "\n",
    "preds = pd.concat([actual, preds], axis = 1)\n",
    "preds = preds.loc[preds[\"Date\"] == \"2012-10-12\"]\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a helper function that is able to format the data correctly for Test Time Augmentation for each of the 4 weeks into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tta_predictions(test_data, experiment_key, time_col, time_group_cols, target_col):\n",
    "    \n",
    "    test_preds = pd.DataFrame()\n",
    "    dates = test_data[time_col].unique()\n",
    "    \n",
    "    # For each date, calculate the prediction from Driverless AI= \n",
    "    for i in dates:\n",
    "        \n",
    "        # Format data for testing\n",
    "        tta_test_data = test_data[test_data[time_col] <= i].copy()\n",
    "        tta_test_data.loc[test_data[time_col] == i, target_col] = None\n",
    "        \n",
    "        # Upload test data to Driverless AI\n",
    "        test_path = \"./tta_test_data.csv\"\n",
    "        tta_test_data.to_csv(test_path, index = False)\n",
    "        test_dai = h2oai.upload_dataset_sync(test_path)\n",
    "        \n",
    "        # Make Predictions\n",
    "        pred_job = h2oai.make_prediction_sync(experiment_key, test_dai.key, \n",
    "                                              output_margin = False, pred_contribs = False)\n",
    "        pred_path = h2oai.download(pred_job.predictions_csv_path, \".\")\n",
    "        \n",
    "        # Save Predictions\n",
    "        preds = pd.read_csv(pred_path)\n",
    "        preds.columns = [\"Prediction\"]\n",
    "        \n",
    "        # Add Date and Time Group columns to the predictions\n",
    "        actuals = tta_test_data[[time_col] + time_group_cols]\n",
    "        actuals = actuals.reset_index(drop = True)\n",
    "        preds = pd.concat([actuals, preds], axis = 1)\n",
    "        preds = preds.loc[preds[time_col] == i]\n",
    "        \n",
    "        # Add actual target to the predictions\n",
    "        preds = pd.merge(preds, test_data[[time_col, target_col] + time_group_cols], \n",
    "                         on = [time_col] + time_group_cols)\n",
    "        test_preds = pd.concat([test_preds, preds], axis = 0)\n",
    "        \n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_predictions_tta = get_tta_predictions(test_data, experiment.key, \"Date\", [\"Store\", \"Dept\"], \"Weekly_Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18676.783203</td>\n",
       "      <td>21904.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45474.324219</td>\n",
       "      <td>48577.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17708.449219</td>\n",
       "      <td>11676.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>35674.765625</td>\n",
       "      <td>39311.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20880.146484</td>\n",
       "      <td>25508.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Store  Dept    Prediction  Weekly_Sales\n",
       "0 2012-10-05      1     1  18676.783203      21904.47\n",
       "1 2012-10-05      1     2  45474.324219      48577.08\n",
       "2 2012-10-05      1     3  17708.449219      11676.98\n",
       "3 2012-10-05      1     4  35674.765625      39311.93\n",
       "4 2012-10-05      1     5  20880.146484      25508.81"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_predictions_tta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Performance\n",
    "\n",
    "Now that we have the forecasted predictions when using Re-Training vs Test Time Augmentation, we can compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Weekly_Sales'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Weekly_Sales'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a916fd53c576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate some error metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrmse_retraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Weekly_Sales\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mforecast_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-Training - RMSE: ${:,.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse_retraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrmse_tta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_predictions_tta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Weekly_Sales\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mforecast_predictions_tta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Weekly_Sales'"
     ]
    }
   ],
   "source": [
    "# Calculate some error metric\n",
    "rmse_retraining = ((forecast_predictions[\"Weekly_Sales\"] - forecast_predictions[\"Prediction\"])**2).mean()**(0.5)\n",
    "print(\"Re-Training - RMSE: ${:,.2f}\".format(rmse_retraining))\n",
    "\n",
    "rmse_tta = ((forecast_predictions_tta[\"Weekly_Sales\"] - forecast_predictions_tta[\"Prediction\"])**2).mean()**(0.5)\n",
    "print(\"Test Time Augmentation - RMSE: ${:,.2f}\".format(rmse_tta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
